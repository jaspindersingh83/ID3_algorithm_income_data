{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas\n",
    "import re \n",
    "r=open('names.txt')\n",
    "cols1=r.read()\n",
    "cols=cols1.split('\\n')\n",
    "columns=[]\n",
    "for i in cols:\n",
    "    value=i.split(':')[0]\n",
    "    columns.append(value)\n",
    "columns=columns[-15:-1]\n",
    "columns.append('high_income')\n",
    "for i in columns:\n",
    "    index=columns.index(i)\n",
    "    i=i.replace('-','_')\n",
    "    columns[index]=i\n",
    "income=pd.read_csv('adult.txt')\n",
    "income.columns=columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:12: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:14: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:16: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/Users/Jaspinder/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>284582</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0   50          6   83311          9             13               2   \n",
       "1   38          4  215646         11              9               0   \n",
       "2   53          4  234721          1              7               2   \n",
       "3   28          4  338409          9             13               2   \n",
       "4   37          4  284582         12             14               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0           4             0     4    1             0             0   \n",
       "1           6             1     4    1             0             0   \n",
       "2           6             0     2    1             0             0   \n",
       "3          10             5     2    0             0             0   \n",
       "4           4             5     4    0             0             0   \n",
       "\n",
       "   hours_per_week  native_country  high_income  \n",
       "0              13              39            0  \n",
       "1              40              39            0  \n",
       "2              40              39            0  \n",
       "3              40               5            0  \n",
       "4              40              39            0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a single column from text categories to numbers\n",
    "col = pandas.Categorical.from_array(income[\"workclass\"])\n",
    "income[\"workclass\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"education\"])\n",
    "income[\"education\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"marital_status\"])\n",
    "income[\"marital_status\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"occupation\"])\n",
    "income[\"occupation\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"relationship\"])\n",
    "income[\"relationship\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"race\"])\n",
    "income[\"race\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"sex\"])\n",
    "income[\"sex\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"native_country\"])\n",
    "income[\"native_country\"] = col.codes\n",
    "col = pandas.Categorical.from_array(income[\"high_income\"])\n",
    "income[\"high_income\"] = col.codes\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8: Overview Of Data Set Entropy**\n",
    "\n",
    "Now that we have a high-level view of how decision trees work, let's explore the details and learn how to perform the splits.\n",
    "\n",
    "We'll use a specific measure to figure out which variables we should split nodes on. Post-split, we'll have two data sets, each containing the rows from one branch of the split.\n",
    "\n",
    "Because we're trying to reach the leaves having only 1s or only 0s in high_income, each split will need to get us closer to that goal.\n",
    "\n",
    "When we split, we'll try to separate as many 0s from 1s in the high_income column as we can. In order to do this, we need a metric for how \"together\" the different values in the high_income column are.\n",
    "\n",
    "Data scientists commonly use a metric called entropy for this purpose. Entropy refers to disorder. The more \"mixed together\" 1s and 0s are, the higher the entropy. A data set consisting entirely of 1s in the high_income column would have low entropy.\n",
    "\n",
    "Entropy, which is not to be confused with entropy from physics, comes from information theory. Information theory is based on probability and statistics, and deals with the transmission, processing, utilization, and extraction of information. A key concept in information theory is the notion of a bit of information. One bit of information is one unit of information.\n",
    "\n",
    "We can represent a bit of information as a binary number because it either has the value 1 or 0. Suppose there's an equal probability of tomorrow being sunny (1) or not sunny (0). If I tell you that it will be sunny, I've given you one bit of information.\n",
    "\n",
    "We can also think of entropy in terms of information. If we flip a coin where both sides are heads, we know upfront that the result will be heads. We gain no new information by flipping the coin, so entropy is 0. On the other hand, if the coin has a heads side and a tails side, there's a 50% probability that it will land on either. Thus, flipping the coin gives us one bit of information -- which side the coin landed on.\n",
    "\n",
    "Entropy can be much more complex, especially when we get to cases with more than two possible outcomes, or differential probabilities. A deep understanding of entropy isn't necessary for constructing decision trees, however. If you'd like, you can read more about entropy at Wikipedia.\n",
    "\n",
    "The formula for entropy looks like this:\n",
    "\n",
    "−∑ci=1P(xi)logbP(xi)\n",
    "\n",
    "We iterate through each unique value in a single column (in this case, high_income), and assign it to ii. We then compute the probability of that value occurring in the data (P(xi)P(xi)). Next we do some multiplication, and sum all of the values together. bb is the base of the logarithm. We commonly use the value 2 for this, but we can also set it to 10 or another value.\n",
    "\n",
    "Let's say we have this data:\n",
    "\n",
    "\n",
    "age    high_income\n",
    "25     1\n",
    "50     1\n",
    "30     0\n",
    "50     0\n",
    "80     1\n",
    "We could compute its entropy like this:\n",
    "\n",
    "−∑i=1cP(xi)logbP(xi)\n",
    "\n",
    "−((2/5∗log22/5)+(3/5∗log23/5))\n",
    "\n",
    "−(−0.5287712379549449+−0.44217935649972373)\n",
    "\n",
    ".97\n",
    "\n",
    "We get less than one \"bit\" of information -- only .97 -- because there are slightly more 1s in the sample data than 0s. This means that if we were predicting a new value, we could guess that the answer is 1 and be right more often than wrong (because there's a .6 probability of the answer being 1). Due to this prior knowledge, we gain less than a full \"bit\" of information when we observe a new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79639620675821887"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_entropy(df,target_col_name):\n",
    "    zero_prob=(df[target_col_name].value_counts()[0])/len(df)\n",
    "    one_prob=(df[target_col_name].value_counts()[1])/len(df)\n",
    "    target_entropy=-1*((zero_prob)*(math.log(zero_prob,2))+(one_prob)*(math.log(one_prob,2)))\n",
    "    return target_entropy\n",
    "income_entropy=cal_entropy(income,'high_income')\n",
    "income_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9: Information Gain**\n",
    "    \n",
    "    \n",
    "We'll need a way to go from computing entropy to figuring out which variable to split on. We can do this using information gain, which tells us which split will reduce entropy the most.\n",
    "\n",
    "Here's the formula for information gain:\n",
    "\n",
    "IG(T,A)=Entropy(T)−∑v∈A|Tv||T|⋅Entropy(Tv)\n",
    "\n",
    "It may look complicated, but we'll break it down. We're computing information gain (IG) for a given target variable (T), as well as a given variable we want to split on (A).\n",
    "\n",
    "To compute it, we first calculate the entropy for TT. Then, for each unique value vv in the variable AA, we compute the number of rows in which AA takes on the value vv, and divide it by the total number of rows. Next, we multiply the results by the entropy of the rows where AA is vv. We add all of these subset entropies together, then subtract from the overall entropy to get information gain.\n",
    "\n",
    "Here's an alternate explanation. We're finding the entropy of each set post-split, weighting it by the number of items in each split, then subtracting from the current entropy. If the result is positive, we've lowered entropy with our split. The higher the result is, the more we've lowered entropy.\n",
    "\n",
    "One strategy for constructing trees is to create as many branches at each node as there are unique values for the variable we're splitting on. So if the variable has three or four values, we'd end up with three or four branches. This approach usually involves more complexity than it's worth and doesn't improve prediction accuracy, but it's worth knowing about.\n",
    "\n",
    "To simplify the calculation of information gain and make splits simpler, we won't do it for each unique value. We'll find the median for the variable we're splitting on instead. Any rows where the value of the variable is below the median will go to the left branch, and the rest of the rows will go to the right branch. To compute information gain, we'll only have to compute entropies for two subsets.\n",
    "\n",
    "Here's an example that uses the same data set we worked with earlier:\n",
    "\n",
    "\n",
    "age    high_income\n",
    "25     1\n",
    "50     1\n",
    "30     0\n",
    "50     0\n",
    "80     1\n",
    "Let's say we wanted to split this data set based on age. First, we calculate the median age, which is 50. Then, we assign any row with a value less than or equal to the median age the value 0 (in a new column named split_age), and the other rows 1.\n",
    "\n",
    "\n",
    "age    high_income    split_age\n",
    "25     1              0\n",
    "50     1              0\n",
    "30     0              0\n",
    "50     0              0\n",
    "80     1              1\n",
    "Now we compute entropy:\n",
    "\n",
    "IG(T,A)=Entropy(T)−∑v∈A(|Tv|/|T|)⋅Entropy(Tv)\n",
    "\n",
    ".97−(((4/5)∗−(1/2∗log21/2+1/2∗log21/2))+−(1/5∗(0∗log20+1∗log21)))\n",
    "\n",
    ".97−((4/5)∗−(−.5+−.5))+(1/5∗−(0+1∗0))\n",
    "\n",
    ".97−(4/5).169\n",
    "\n",
    "We end up with .17, which means that we gain .17 bits of information by splitting our data set on the age variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22410907689234416"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Compute the information gain for splitting on the age column of income.\n",
    "##First, compute the median of age.\n",
    "##Then, assign anything less than or equal to the median to the left branch, and anything greater than the median to the right branch.\n",
    "###Compute the information gain and assign it to age_information_gain.\n",
    "def cal_entropy(df,target_col_name):\n",
    "    zero_prob=(df[target_col_name].value_counts()[0])/len(df)\n",
    "    one_prob=(df[target_col_name].value_counts()[1])/len(df)\n",
    "    target_entropy=-1*((zero_prob)*(math.log(zero_prob,2))+(one_prob)*(math.log(one_prob,2)))\n",
    "    return target_entropy\n",
    "\n",
    "def information_gain(df,col_name,target_col_name):\n",
    "    median_col=df[col_name].median()\n",
    "    split_col_name='split_'+col_name\n",
    "    df[split_col_name]=df[col_name]>median_col\n",
    "    zero_split_col_prob=df[split_col_name].value_counts()[0]/len(df)\n",
    "    one_split_col_prob=df[split_col_name].value_counts()[1]/len(df)\n",
    "    df_split_col_0=df[df[split_col_name]==0]\n",
    "    df_split_col_0_target_entropy=cal_entropy(df_split_col_0,target_col_name)\n",
    "    df_split_col_1=df[df[split_col_name]==1]\n",
    "    df_split_col_1_target_entropy=cal_entropy(df_split_col_0,target_col_name)\n",
    "    IG_summation_value=zero_split_col_prob*df_split_col_0_target_entropy+one_split_col_prob*df_split_col_1_target_entropy\n",
    "    col_information_gain=cal_entropy(df,target_col_name)-IG_summation_value\n",
    "    return col_information_gain\n",
    "\n",
    "age_information_gain=information_gain(income,'age','high_income')\n",
    "age_information_gain\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22410907689234416, -0.0004581269315567793, 0.031508157028117822, -0.15314207819252945, 0.030877405216549692, 0.1309291786180935, -0.10259225780768544]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22410907689234416"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Create a list called information_gains.\n",
    "###It should contain, in order, the information gain from splitting on these columns: age, workclass, education_num, marital_status, occupation, relationship, race, sex, hours_per_week, native_country.\n",
    "##Find the highest value in the information_gains list, and assign the corresponding column name to highest_gain.\n",
    "\n",
    "columns = [\"age\",'native_country','workclass','marital_status','occupation','hours_per_week','relationship']\n",
    "information_gains=[]\n",
    "for i in columns:\n",
    "    value=information_gain(income,i,'high_income')\n",
    "    information_gains.append(value)\n",
    "print(information_gains)\n",
    "max(information_gains)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
